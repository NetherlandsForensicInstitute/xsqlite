''' _export.py - functionality related to exporting data from SQLite3 dbs.

Copyright (c) 2022 Netherlands Forensic Institute - MIT License
'''

from binascii import hexlify as _hexlify
from collections import namedtuple as _nt
from bitstring import BitStream as _BS
from bitstring import ConstBitStream as _CB
from os.path import abspath as _abspath
from os.path import expanduser as _expanduser
from os.path import exists as _exists
import bigfloat as _bigfloat
import xlsxwriter as _xlsxwriter
import csv as _csv

from . import _exceptions

########
# dump #
########

# this section contains functionality related to creating a dump similar to the
# sqlite3 native 'dump' command


def create_table_statement(db, tablename):
    ''' returns the CREATE TABLE statement for the given table

    The CREATE TABLE is appended with semi-colon and newline, to make it
    suitable to include in a database ".dump"

    Arguments:
    - db      : the parsed database object
    - outfile : the path of the output file to use
    '''
    sql = db.sqlite_master.tables[tablename].sql
    return sql+';\n'


def insert_statements(db, tablename):
    ''' generates a sequence of INSERT INTO statements for given table

    This creates output similar to SQLite's .dump command, mainly used for
    validation purposes.

    Arguments:
    - db      : the parsed database object
    - outfile : the path of the output file to use
    '''
    tbl = db.tables[tablename]
    # this behaviour seems to have changed with more recent versions of sqlite3
    #template = 'INSERT INTO "' + tablename + '" VALUES({:s});\n'
    template = 'INSERT INTO ' + tablename + ' VALUES({:s});\n'
    records = (tbl.viewer.user_view(r) for r in db.rowidrecords(tbl.rootpage))
    for r in records:
        vals = [stringlify(v, 'NULL') for v in r.values.values()]
        yield template.format(','.join(vals))


def tabledump(db, tablename):
    ''' produce sequence of strings similar to SQLite3's .dump command for
    given table

    Arguments:
    - db      : the parsed database object
    - outfile : the path of the output file to use
    '''

    yield create_table_statement(db, tablename)
    for statement in insert_statements(db, tablename):
        yield statement


def dumpdb(db, outfile):
    ''' mimic the sqlite3 ".dump" command

    Dumps the given database object to the given outfile in a format
    similar to that generated by  SQLite's native .dump command. This is here
    mainly for allowing us to compare our results with those of the .dump
    command as a means of validating our parser for allocated data.

    Note that in some cases the order in which INDEX and TRIGGER statements are
    exported might differ from the order which this is done by the native
    sqlite3 ".dump" command. In such cases, one could sort the output before
    comparing.

    Also note that CREATE VIRTUAL TABLE statements are not yet supported, which
    might also lead to differences between the native sqlite3 ".dump" output
    and the output generated by this function.

    Arguments:
    - db      : the parsed database object
    - outfile : the path of the output file to use
    '''

    if isinstance(outfile, str):
        outfile = _abspath(_expanduser(outfile))
        if _exists(outfile):
            raise RuntimeError('refusing to overwrite output file')
        with open(outfile, 'wt') as f:
            _dumpdb(db, f)
    else:
        _dumpdb(db, outfile)


def _dumpdb(db, f):
    ''' dumps database to opened file object, see dumpdb '''

    # begin transaction
    f.write('PRAGMA foreign_keys=OFF;\nBEGIN TRANSACTION;\n')

    # dump the tables
    for tablename in db.tables.keys():
        # skip sqlite_master and sqlite_sequence
        if tablename.startswith('sqlite_'):
            continue
        for statement in tabledump(db, tablename):
            f.write(statement)
        f.flush()

    # prepare the sqlite_sequence table
    if 'sqlite_sequence' in db.tables:
        tbl = db.tables['sqlite_sequence']
        # newer versions seem to include this statement even if there are no
        # records present
        f.write('DELETE FROM sqlite_sequence;\n')
        #if len(list(db.rowidrecords(tbl.rootpage))) > 0:
        #    #  start with DELETE FROM statement if the table has records
        #    f.write('DELETE FROM sqlite_sequence;\n')
        for statement in insert_statements(db, 'sqlite_sequence'):
            f.write(statement)
        f.flush()

    # write CREATE INDEX statements
    for index in db.sqlite_master.indices.values():
        if index.sql is not None:
            f.write(index.sql+';\n')

    # write CREATE TRIGGER statements
    for trigger in db.sqlite_master.triggers.values():
        if trigger.sql is not None:
            f.write(trigger.sql+';\n')

    # write CREATE VIEW statements
    for view in db.sqlite_master.views.values():
        if view.sql is not None:
            f.write(view.sql+';\n')

    # finish up with a commit
    f.write('COMMIT;\n')


#####################
# string conversion #
#####################

# this section contains functionality related to string conversion, implemented
# in a similar manner as in the sqlite3 code base.

def stringlify(value, nullvalue='NULL', dumpformat=True, tsvformat=False):
    ''' Takes a column value and turns it into a string.

    This function detects the type of the passed value and acts accordingly.
    BLOB data is generated in the X'ABCD'-notation. TEXT values are
    single-quoted. NULL values are represented with an empty string by default.
    When nullvalue is set to some other string it is used instead. For
    mimicking sqlite3's native .dump command use 'NULL'.

    This is useful when exporting records to a text-based file, similar to the
    .dump command in SQLite. Single-quotes are used as string-delimiter. When
    single-quotes occur within a string, these are escaped with another
    single-quote, similar to SQLite's .dump command behavior.
    '''

    if not isinstance(nullvalue, str):
        raise ValueError('provide a string to represent NULL')

    if value == nullvalue:
        raise ValueError('the nullvalue exists in a column, which is ambiguous')

    if isinstance(value, bytes):
        return "X'" + _hexlify(value).decode('utf-8').lower() + "'"

    elif isinstance(value, str) and dumpformat is True:
        # quotes and newlines are handled differently when performing a dump
        # single quote a strings, and replace single quotes with escaped quote ('')
        res = "'"+value.replace("'", "''")+"'"
        if '\r' in res:
            # when a newline exists, the dump output in recent sqlite versions
            # uses the replace function syntax in the output. Mimic this behaviour
            res = "replace("+res.replace('\r','\\r')+",'\\r',char(13))"
        if '\n' in res:
            # when a newline exists, the dump output in recent sqlite versions
            # uses the replace function syntax in the output. Mimic this behaviour
            res = "replace("+res.replace('\n','\\n')+",'\\n',char(10))"

        return res

    elif isinstance(value, str) and tsvformat is True:
        if '\n' in value:
            return value.replace('\n','\\n')
        return value

    elif value is None:
        return nullvalue

    elif isinstance(value, float):

        # NOTE: this seems to have changed with more recent versions of
        # sqlite3. Checked on 09-10-2018 and there are significant changes
        # between VXPrintf function in version 3.8.7.1 and 3.22.0. So this 
        # may produce different results in some records.

        # As it turns out, sqlite3 uses the x86 extended float precision (80
        # bits, with 64 bit significand) in memory, whereas the in-file storage
        # is a normal double precision IEEE 754 float, similar to the standard
        # python float (with 53 bit significand). This, in combination with the
        # fact that sqlite implements its own printf module (main functionality
        # in sqlite3VXPrintf) function led to the sitation where our string
        # representation did not exactly match that of sqlite. This is now
        # fixed by using proper precision when conversion to string is
        # performed. Note that both outputs did evaluate to the exact same IEEE
        # 754 float, the differences occur since the precision in the .dump
        # output is larger than the actually supported precision, which is done
        # by sqlite3 in order to obtain the exact same value upon subsequent
        # import.

        with _bigfloat.precision(64):
            # convert to bigfloat with 64 bits precision
            val = _bigfloat.BigFloat(value)
            # store .15g representation in r1
            r1 = sqlite3VXPrintf(val, 1)
            # parse the converted value back into r2
            r2 = _bigfloat.BigFloat.exact(r1, precision=64)
            # compare r2 with original as IEEE 754 float (python native float)
            if float(val) == float(r2):
                # exact match, save to represent as .15g
                return r1
            else:
                # not an exact match, need .20e representation
                return sqlite3VXPrintf(val, 2)

    else:
        return str(value)


def sqlite3VXPrintf(value, case=1):
    ''' Format floating point value similar to the way this is performed by the
    sqlite3VXPrintf function (in printf.c) as called (indirectly) from the
    quoteFunc (in func.c). When case=1, the %.15g formatting is returned, when
    case = 2, the %.20e formatting is returned.

    We cannot just use the python equivalent of .15g or .20e, since we've seen
    that the precision for the 'e' notation as produced by sqlite may differ.
    Additionally, the rounding and removal of terminating zeroes works a bit
    differently. In order to be able to verify our dumps with those produced by
    the native sqlite3 command we need to port this stuff to python. Only the
    bare minimum required for etGENERIC, etEXP and etFLOAT formatting (sqlite3
    terminology) is ported.
    '''

    # realvalue will be changed, keep value for normal .15g representation
    realvalue = value

    # some of the xtypes, just so we can use the same names here
    etFLOAT = 2
    etEXP = 3
    etGENERIC = 4

    if case == 1:
        # precision of 15 is decremented in line 467 for etGENERIC
        precision = 14
        xtype = etGENERIC
        precision -= 1

    elif case == 2:
        precision = 20
        xtype = etEXP
    else:
        raise ValueError('case can be one of [1,2]')

    # line 459, determine prefix
    prefix = ''
    if realvalue < 0.0:
        realvalue = -realvalue
        prefix = '-'

    # line 472, NaN
    if _bigfloat.is_nan(realvalue):
        return 'NaN'

    # line 477, normalize to within (10.0, 1.0] range:
    exp = 0
    scale = 1.0
    result = ''
    # add prefix to result
    result += prefix

    # this seems to be updated in versions at higher than at least 3.8.7.1, on
    # which the previous version was based. This I changed here, but the entire
    # function needs revisiting, since I get rounding differences between the
    # xsqlite export and the native export
    if realvalue > 0.0:
        while (realvalue >= 1e100 * scale and exp <= 350):
            scale *= 1e100
            exp += 100
        while (realvalue >= 1e10 * scale and exp <= 350):
            scale *= 1e10
            exp += 10
        while (realvalue >= 10.0 * scale and exp <= 350):
            scale *= 10.0
            exp += 1
        realvalue /= scale
        while realvalue < 1e-8:
            realvalue *= 1e8
            exp -= 8
        while realvalue < 1.0:
            realvalue *= 10.0
            exp -= 1

        if exp > 350:
            result += 'Inf'
            return result

    # line 468, determine rounder
    rounder = 0.5
    for i in range(precision, 0, -1):
        rounder *= 0.1

    # line 503, convert etGENERIC to either etEXP or etFLOAT
    realvalue += rounder
    if realvalue >= 10.0:
        realvalue *= 0.1
        exp += 1

    # line 507, determine xtype based on exponent and precision
    if xtype == etGENERIC:
        if (exp < -4 or exp > precision):
            xtype = etEXP
        else:
            # at this point, everything is similar to python .15g formatting
            result = '{:.15g}'.format(float(value))
            # except for the additional .0 at the end
            if '.' not in result:
                result += '.0'
            return result

    # if we get here, xtype == etEXP, so no need to copy all checks

    # line 537, digits prior to decimal point (and part at line 498)
    # for etEXP this is always between 1 and 10, so e2 == 0
    # (no need to implement loop as in sqlite3VXPrintf)
    # add a digit and shift digits left (similar to et_getdigit)
    digit = int(realvalue)
    realvalue = (realvalue - digit) * 10
    result += str(digit)
    # line 545, decimal point (for etEXP always shown)
    result += '.'

    # line 555, significant digits after decimal point
    while precision > 0:
        precision -= 1
        digit = int(realvalue)
        realvalue = (realvalue - digit) * 10
        result += str(digit)

    # line 559, remove trailing zero's
    result = result.rstrip('0')

    # line 571, add the exponent with proper sign
    result += 'e'
    if exp < 0:
        result += '-'
        exp = -exp
    else:
        result += '+'
    if exp >= 100:
        result += '{:03d}'.format(exp)
    else:
        result += '{:02d}'.format(exp)

    return result


###################
# views to tuples #
###################

# this section contains functionality related to converting the different
# record views to tuples that can be exported

def view_to_tuple(view, tsvformat=False):
    ''' convert the given view to a flat tuple (i.e. unpack the individual field values)

    A view contains several fixed fields, followed by a 'values' field that contains
    the records column values. This function takes these individual values and extends
    the tuple of fixed fields with the tuple of these individual values
    '''

    # record contains multiple fields, one of which is a 'values' field that contains
    # the individual column values. Unpack the fields as a dictionary
    fields = view._asdict()
    # extract the values field and drop it from the original fields dictionary
    column_values = fields.pop('values')
    fixed = [v for k, v in fields.items()]
    colvals = [stringlify(v, dumpformat=False, tsvformat=tsvformat) for v in column_values.values()]
    towrite = fixed + colvals
    return tuple(towrite)


def forensic_header(tbl):
    ''' create a header for the forensic view for the given table '''

    colnames = [c.name.lstrip('"\'[`').rstrip('"\']`') for c in tbl.columns]
    fieldnames = tbl.viewer._forensic_view._fields[:-1]
    return fieldnames + tuple(colnames)


def detailed_header(tbl):
    ''' create a header for the detailed view for the given table '''

    colnames = [c.name.lstrip('"\'[`').rstrip('"\']`') for c in tbl.columns]
    fieldnames = tbl.viewer._detailed_view._fields[:-1]
    return fieldnames + tuple(colnames)


def user_header(tbl):
    ''' create a header for the user view for the given table '''

    colnames = [c.name.lstrip('"\'[`').rstrip('"\']`') for c in tbl.columns]
    fieldnames = tbl.viewer._user_view._fields[:-1]
    return fieldnames + tuple(colnames)


###############
# xlsx export #
###############

# functionality related to exporting to xlsx

class XLSXWriter():
    ''' object that can be used to write results to an xslx file '''


    def __init__(s, filename):
        ''' open an xlsx workbook for writing '''

        if isinstance(filename, str):
            filename = _abspath(_expanduser(filename))
            if _exists(filename):
                raise RuntimeError('refusing to overwrite output file')
        else:
            raise _exceptions.InvalidArgumentException("provide filename")

        s.workbook = _xlsxwriter.Workbook(filename, {'constant_memory': True})
        s.worksheets = {}
        s.worksheet_rowpointers = {}


    def __enter__(s):
        ''' we can be used as a context manager Class '''

        return s


    def __exit__(s, type, value, traceback):
        ''' added so we can be used as a context manager Class '''

        s.workbook.close()


    def close(s):
        ''' close the workbook '''

        s.workbook.close()


    def add_sheet(s, sheetname):
        ''' add a worksheet with the given name to the workbook '''

        if sheetname in s.worksheets:
            raise _exceptions.InvalidArgumentException("worksheet already exists")
        sheet = s.workbook.add_worksheet(sheetname)
        s.worksheets[sheetname] = sheet
        s.worksheet_rowpointers[sheetname] = 0


    def write_row(s, sheetname, row):
        ''' write the given row to the given sheet

        Note that the controlcharacters \x00 through \x08 and \x0b through \x1f
        are escaped by xlsxwriter to the _xHHHH_ format in the excel output.
        This occurs mostly in false positives or in records that are partially
        overwritten.
        '''

        row_ptr = s.worksheet_rowpointers[sheetname]
        sheet = s.worksheets[sheetname]
        if hasattr(row, 'values'):
            # the row is actually a view, convert to full tuple
            row = view_to_tuple(row)
        for col, val in enumerate(row):
            if isinstance(val, list):
                val = str(val)
            if isinstance(val, str):
                sheet.write_string(row_ptr, col, val)
            else:
                sheet.write(row_ptr, col, str(val))
        s.worksheet_rowpointers[sheetname] += 1


    def write_detailed_header(s, sheetname, table):
        ''' write a detailed header for the given table to the given sheet '''

        hdr = detailed_header(table)
        s.write_row(sheetname, hdr)


    def write_forensic_header(s, sheetname, table):
        ''' write a forensic header for the given table to the given sheet '''

        hdr = forensic_header(table)
        s.write_row(sheetname, hdr)


    def write_user_header(s, sheetname, table):
        ''' write a user header for the given table to the given sheet '''

        hdr = user_header(table)
        s.write_row(sheetname, hdr)


##############
# tsv export #
##############

# functionality related to export to tsv

class TSVWriter():
    ''' class that manages writing results to a tsv file '''


    def __init__(s, filename):
        ''' open a tsv file for writing '''

        if isinstance(filename, str):
            filename = _abspath(_expanduser(filename))
            if _exists(filename):
                raise RuntimeError('refusing to overwrite output file')
        else:
            raise _exceptions.InvalidArgumentException("provide filename")

        s._csvfile = open(filename, 'w', newline='')
        s.writer = _csv.writer(s._csvfile, delimiter='\t',quotechar="'", quoting=_csv.QUOTE_MINIMAL)


    def __enter__(s):
        ''' we can be used as a context manager Class '''

        return s


    def __exit__(s, type, value, traceback):
        ''' added so we can be used as a context manager Class '''

        s._csvfile.close()


    def close(s):
        ''' close the tsv file '''

        s._csvfile.close()


    def write_row(s, row):
        ''' write the given row to the tsv file

        Note that newlines or other control characters might prevent proper
        import into excel or libreoffice, although we try to double escape these.
        '''

        if hasattr(row, 'values'):
            # the row is actually a view, convert to full tuple
            row = view_to_tuple(row, tsvformat=True)
        s.writer.writerow(row)


    def write_detailed_header(s, table):
        ''' write a detailed header for the given table to the tsv file '''

        hdr = detailed_header(table)
        s.write_row(hdr)


    def write_forensic_header(s, table):
        ''' write a forensic header for the given table to the tsv file '''

        hdr = forensic_header(table)
        s.write_row(hdr)


    def write_user_header(s, table):
        ''' write a user header for the given table to the tsv file '''

        hdr = user_header(table)
        s.write_row(hdr)
